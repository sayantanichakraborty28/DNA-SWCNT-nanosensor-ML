{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDErdxfLlmOr",
        "outputId": "1c075e83-5267-4b20-a962-2477a91af0b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.3.5-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Downloading rdkit-2025.3.5-cp312-cp312-manylinux_2_28_x86_64.whl (36.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "NCE1xKnRlqdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload manually with button \"Choose Files\"\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "uploaded = files.upload()\n",
        "df = pd.read_excel('HOMO-LUMO-energies.xlsx')\n",
        "smiles_list = df[\"Smiles\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "ICMH-gQLmMMu",
        "outputId": "8096b09d-f512-4bad-b202-cead8f0389a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8cf90b66-883d-4e3d-b129-9ad67923310e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8cf90b66-883d-4e3d-b129-9ad67923310e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving HOMO-LUMO-energies.xlsx to HOMO-LUMO-energies.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Morgan"
      ],
      "metadata": {
        "id": "pLZ2mgX8urhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdFingerprintGenerator\n",
        "from rdkit import DataStructs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048\n",
        "RADIUS = 2\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)  # seeds 0..199\n",
        "\n",
        "# For Case 2 thresholds (63-molecule dataset)\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # needs columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_initial_only\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_initial_only.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_morgan(smiles_list, radius=2, nBits=2048):\n",
        "    gen = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=nBits)\n",
        "    mols = [Chem.MolFromSmiles(s) if Chem.MolFromSmiles(s) is not None else Chem.MolFromSmiles(\"\")\n",
        "            for s in smiles_list]\n",
        "    X = np.zeros((len(mols), nBits), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        fp = gen.GetFingerprint(m)\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X\n",
        "\n",
        "def bit_presence(X):\n",
        "    return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask):\n",
        "    return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    meta = {}\n",
        "    orig_dim = X_init.shape[1]\n",
        "    meta[\"orig_dim\"] = orig_dim\n",
        "\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\n",
        "            \"rule\": rule,\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(orig_dim, new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"final_dim\": new_dim,\n",
        "            \"dropped\": 0,\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(orig_dim, new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"rule\": \"case2_after_fold\",\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped_after_fold\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_morgan(smiles, radius=RADIUS, nBits=N_BITS)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE: Train on full 2048-bit fingerprints (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRrbf_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "            X0, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "        )\n",
        "        model = SVR(kernel=\"rbf\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean = float(np.mean(r2s))\n",
        "baseline_std = float(np.std(r2s))\n",
        "print(f\"Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = []\n",
        "summary_rows.append({\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 2048-bit Morgan\"\n",
        "})\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRrbf_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "                X_case, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "            )\n",
        "            model = SVR(kernel=\"rbf\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "\n",
        "    r2_mean = float(np.mean(r2s))\n",
        "    r2_std = float(np.std(r2s))\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": r2_mean,\n",
        "        \"R2_std\": r2_std,\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== SVR (RBF) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z_fG9XKuGo9",
        "outputId": "b037317c-6b6a-4d4b-9f81-24c7032f47d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline (2048 bits) -> Mean R2: 0.141265, Std: 0.254910\n",
            "\n",
            "=== SVR (RBF) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim  R2_mean   R2_std\n",
            "baseline      2048       2048 0.141265 0.254910\n",
            "       1      2048        344 0.138462 0.255285\n",
            "       2      2048         87 0.189947 0.298384\n",
            "  3_1024      2048       1024 0.113121 0.255248\n",
            "   3_512      2048        512 0.110793 0.262404\n",
            "  4_1024      2048         92 0.137222 0.300582\n",
            "   4_512      2048        104 0.104035 0.290882\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_initial_only/summary_results_initial_only.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdFingerprintGenerator\n",
        "from rdkit import DataStructs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048\n",
        "RADIUS = 2\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)  # seeds 0..199\n",
        "\n",
        "# For Case 2 thresholds (63-molecule dataset)\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # needs columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_initial_only\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_initial_only.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_morgan(smiles_list, radius=2, nBits=2048):\n",
        "    gen = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=nBits)\n",
        "    mols = [Chem.MolFromSmiles(s) if Chem.MolFromSmiles(s) is not None else Chem.MolFromSmiles(\"\")\n",
        "            for s in smiles_list]\n",
        "    X = np.zeros((len(mols), nBits), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        fp = gen.GetFingerprint(m)\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X\n",
        "\n",
        "def bit_presence(X):\n",
        "    return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask):\n",
        "    return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    meta = {}\n",
        "    orig_dim = X_init.shape[1]\n",
        "    meta[\"orig_dim\"] = orig_dim\n",
        "\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\n",
        "            \"rule\": rule,\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(orig_dim, new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"final_dim\": new_dim,\n",
        "            \"dropped\": 0,\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(orig_dim, new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"rule\": \"case2_after_fold\",\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped_after_fold\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_morgan(smiles, radius=RADIUS, nBits=N_BITS)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE: Train on full 2048-bit fingerprints (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRlinear_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "            X0, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "        )\n",
        "        model = SVR(kernel=\"linear\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean = float(np.mean(r2s))\n",
        "baseline_std = float(np.std(r2s))\n",
        "print(f\"Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = []\n",
        "summary_rows.append({\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 2048-bit Morgan\"\n",
        "})\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRlinear_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "                X_case, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "            )\n",
        "            model = SVR(kernel=\"linear\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "\n",
        "    r2_mean = float(np.mean(r2s))\n",
        "    r2_std = float(np.std(r2s))\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": r2_mean,\n",
        "        \"R2_std\": r2_std,\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== SVR (RBF) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAlry6_RuNnu",
        "outputId": "ca68b69e-7b56-4413-ef40-e6caa07092c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline (2048 bits) -> Mean R2: 0.152656, Std: 0.417197\n",
            "\n",
            "=== SVR (RBF) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim   R2_mean   R2_std\n",
            "baseline      2048       2048  0.152656 0.417197\n",
            "       1      2048        344  0.152656 0.417197\n",
            "       2      2048         87 -0.237658 0.914480\n",
            "  3_1024      2048       1024  0.062612 0.420229\n",
            "   3_512      2048        512 -0.033586 0.505815\n",
            "  4_1024      2048         92 -0.574159 1.003556\n",
            "   4_512      2048        104 -0.686001 0.938002\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_initial_only/summary_results_initial_only.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdFingerprintGenerator\n",
        "from rdkit import DataStructs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048\n",
        "RADIUS = 2\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)  # seeds 0..199\n",
        "\n",
        "# For Case 2 thresholds (63-molecule dataset)\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # needs columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_initial_only\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_initial_only.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_morgan(smiles_list, radius=2, nBits=2048):\n",
        "    gen = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=nBits)\n",
        "    mols = [Chem.MolFromSmiles(s) if Chem.MolFromSmiles(s) is not None else Chem.MolFromSmiles(\"\")\n",
        "            for s in smiles_list]\n",
        "    X = np.zeros((len(mols), nBits), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        fp = gen.GetFingerprint(m)\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X\n",
        "\n",
        "def bit_presence(X):\n",
        "    return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask):\n",
        "    return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    meta = {}\n",
        "    orig_dim = X_init.shape[1]\n",
        "    meta[\"orig_dim\"] = orig_dim\n",
        "\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\n",
        "            \"rule\": rule,\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(orig_dim, new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"final_dim\": new_dim,\n",
        "            \"dropped\": 0,\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(orig_dim, new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"rule\": \"case2_after_fold\",\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped_after_fold\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_morgan(smiles, radius=RADIUS, nBits=N_BITS)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE: Train on full 2048-bit fingerprints (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRsigmoid_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "            X0, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "        )\n",
        "        model = SVR(kernel=\"sigmoid\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean = float(np.mean(r2s))\n",
        "baseline_std = float(np.std(r2s))\n",
        "print(f\"Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = []\n",
        "summary_rows.append({\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 2048-bit Morgan\"\n",
        "})\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRsigmoid_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "                X_case, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "            )\n",
        "            model = SVR(kernel=\"sigmoid\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "\n",
        "    r2_mean = float(np.mean(r2s))\n",
        "    r2_std = float(np.std(r2s))\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": r2_mean,\n",
        "        \"R2_std\": r2_std,\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== SVR (RBF) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "211S9se8uX9l",
        "outputId": "5ad51073-f799-4ddf-9ccb-632a44aaee11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline (2048 bits) -> Mean R2: 0.263703, Std: 0.257836\n",
            "\n",
            "=== SVR (RBF) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim  R2_mean   R2_std\n",
            "baseline      2048       2048 0.263703 0.257836\n",
            "       1      2048        344 0.265040 0.260669\n",
            "       2      2048         87 0.259356 0.327856\n",
            "  3_1024      2048       1024 0.195780 0.274115\n",
            "   3_512      2048        512 0.166084 0.294891\n",
            "  4_1024      2048         92 0.159021 0.347371\n",
            "   4_512      2048        104 0.100642 0.351531\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_initial_only/summary_results_initial_only.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MACCS"
      ],
      "metadata": {
        "id": "Aoxpq3xHzDlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import MACCSkeys\n",
        "from rdkit import DataStructs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 166        # MACCS effective length (RDKit returns 167; we drop bit0)\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "# Cases:\n",
        "# 1: drop never-seen bits\n",
        "# 2: drop never-seen, rare (<3), ubiquitous (>60) bits\n",
        "# 3_k: fold 166 -> k by modulo (no dropping)\n",
        "# 4_k: fold, then Case-2 dropping on folded space\n",
        "CASES = [\"1\", \"2\", \"3_83\", \"3_42\", \"4_83\", \"4_42\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # needs columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_MACCS\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_MACCS.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_maccs(smiles_list):\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    # RDKit MACCS = 167 bits; bit 0 is unused -> slice [1:] to get 166 bits\n",
        "    X = np.zeros((len(mols), 167), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        if m is None:\n",
        "            continue\n",
        "        fp = MACCSkeys.GenMACCSKeys(m)  # ExplicitBitVect length 167\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X[:, 1:]  # drop the unused first bit -> shape (N, 166)\n",
        "\n",
        "def bit_presence(X):\n",
        "    return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask):\n",
        "    return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    meta = {}\n",
        "    orig_dim = X_init.shape[1]\n",
        "    meta[\"orig_dim\"] = orig_dim\n",
        "\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\n",
        "            \"rule\": rule,\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(orig_dim, new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"final_dim\": new_dim,\n",
        "            \"dropped\": 0,\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(orig_dim, new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"rule\": \"case2_after_fold\",\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped_after_fold\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_maccs(smiles)     # shape (N, 166)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRrbf_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "            X0, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "        )\n",
        "        model = SVR(kernel=\"rbf\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean = float(np.mean(r2s))\n",
        "baseline_std = float(np.std(r2s))\n",
        "print(f\"MACCS Baseline (166 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = []\n",
        "summary_rows.append({\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 166-bit MACCS (bit0 dropped)\"\n",
        "})\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRrbf_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "                X_case, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "            )\n",
        "            model = SVR(kernel=\"rbf\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "\n",
        "    r2_mean = float(np.mean(r2s))\n",
        "    r2_std = float(np.std(r2s))\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": r2_mean,\n",
        "        \"R2_std\": r2_std,\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== MACCS SVR (RBF) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSRcmT6uzFxM",
        "outputId": "be785590-e879-4823-aed8-afd74979b24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MACCS Baseline (166 bits) -> Mean R2: 0.256958, Std: 0.232958\n",
            "\n",
            "=== MACCS SVR (RBF) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim  R2_mean   R2_std\n",
            "baseline       166        166 0.256958 0.232958\n",
            "       1       166        106 0.254371 0.233333\n",
            "       2       166         69 0.279476 0.221913\n",
            "    3_83       166         83 0.228459 0.226267\n",
            "    3_42       166         42 0.263090 0.252067\n",
            "    4_83       166         64 0.236713 0.225615\n",
            "    4_42       166         40 0.262927 0.252096\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_MACCS/summary_results_MACCS.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import MACCSkeys\n",
        "from rdkit import DataStructs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 166        # MACCS effective length (RDKit returns 167; we drop bit0)\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "# Cases:\n",
        "# 1: drop never-seen bits\n",
        "# 2: drop never-seen, rare (<3), ubiquitous (>60) bits\n",
        "# 3_k: fold 166 -> k by modulo (no dropping)\n",
        "# 4_k: fold, then Case-2 dropping on folded space\n",
        "CASES = [\"1\", \"2\", \"3_83\", \"3_42\", \"4_83\", \"4_42\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # needs columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_MACCS\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_MACCS.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_maccs(smiles_list):\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    # RDKit MACCS = 167 bits; bit 0 is unused -> slice [1:] to get 166 bits\n",
        "    X = np.zeros((len(mols), 167), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        if m is None:\n",
        "            continue\n",
        "        fp = MACCSkeys.GenMACCSKeys(m)  # ExplicitBitVect length 167\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X[:, 1:]  # drop the unused first bit -> shape (N, 166)\n",
        "\n",
        "def bit_presence(X):\n",
        "    return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask):\n",
        "    return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    meta = {}\n",
        "    orig_dim = X_init.shape[1]\n",
        "    meta[\"orig_dim\"] = orig_dim\n",
        "\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\n",
        "            \"rule\": rule,\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(orig_dim, new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"final_dim\": new_dim,\n",
        "            \"dropped\": 0,\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(orig_dim, new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"rule\": \"case2_after_fold\",\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped_after_fold\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_maccs(smiles)     # shape (N, 166)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRlinear_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "            X0, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "        )\n",
        "        model = SVR(kernel=\"linear\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean = float(np.mean(r2s))\n",
        "baseline_std = float(np.std(r2s))\n",
        "print(f\"MACCS Baseline (166 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = []\n",
        "summary_rows.append({\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 166-bit MACCS (bit0 dropped)\"\n",
        "})\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRlinear_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "                X_case, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "            )\n",
        "            model = SVR(kernel=\"linear\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "\n",
        "    r2_mean = float(np.mean(r2s))\n",
        "    r2_std = float(np.std(r2s))\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": r2_mean,\n",
        "        \"R2_std\": r2_std,\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== MACCS SVR (RBF) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4Dn2HHgzNPt",
        "outputId": "8d75b04b-0d17-441d-cd26-884f96ef81d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MACCS Baseline (166 bits) -> Mean R2: -0.548034, Std: 0.942605\n",
            "\n",
            "=== MACCS SVR (RBF) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim   R2_mean   R2_std\n",
            "baseline       166        166 -0.548034 0.942605\n",
            "       1       166        106 -0.548034 0.942605\n",
            "       2       166         69 -0.489863 0.919480\n",
            "    3_83       166         83 -0.543728 0.815668\n",
            "    3_42       166         42 -0.716796 0.961797\n",
            "    4_83       166         64 -0.487042 0.776770\n",
            "    4_42       166         40 -0.687250 0.963346\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_MACCS/summary_results_MACCS.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import MACCSkeys\n",
        "from rdkit import DataStructs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 166        # MACCS effective length (RDKit returns 167; we drop bit0)\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "# Cases:\n",
        "# 1: drop never-seen bits\n",
        "# 2: drop never-seen, rare (<3), ubiquitous (>60) bits\n",
        "# 3_k: fold 166 -> k by modulo (no dropping)\n",
        "# 4_k: fold, then Case-2 dropping on folded space\n",
        "CASES = [\"1\", \"2\", \"3_83\", \"3_42\", \"4_83\", \"4_42\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # needs columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_MACCS\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_MACCS.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_maccs(smiles_list):\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    # RDKit MACCS = 167 bits; bit 0 is unused -> slice [1:] to get 166 bits\n",
        "    X = np.zeros((len(mols), 167), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        if m is None:\n",
        "            continue\n",
        "        fp = MACCSkeys.GenMACCSKeys(m)  # ExplicitBitVect length 167\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X[:, 1:]  # drop the unused first bit -> shape (N, 166)\n",
        "\n",
        "def bit_presence(X):\n",
        "    return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask):\n",
        "    return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    meta = {}\n",
        "    orig_dim = X_init.shape[1]\n",
        "    meta[\"orig_dim\"] = orig_dim\n",
        "\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\n",
        "            \"rule\": rule,\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(orig_dim, new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"final_dim\": new_dim,\n",
        "            \"dropped\": 0,\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(orig_dim, new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"rule\": \"case2_after_fold\",\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped_after_fold\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_maccs(smiles)     # shape (N, 166)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRsigmoid_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "            X0, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "        )\n",
        "        model = SVR(kernel=\"sigmoid\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean = float(np.mean(r2s))\n",
        "baseline_std = float(np.std(r2s))\n",
        "print(f\"MACCS Baseline (166 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = []\n",
        "summary_rows.append({\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 166-bit MACCS (bit0 dropped)\"\n",
        "})\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRsigmoid_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "                X_case, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "            )\n",
        "            model = SVR(kernel=\"sigmoid\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "\n",
        "    r2_mean = float(np.mean(r2s))\n",
        "    r2_std = float(np.std(r2s))\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": r2_mean,\n",
        "        \"R2_std\": r2_std,\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== MACCS SVR (SIGMOID) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soPLvbcdzmss",
        "outputId": "a786bebf-27b2-49dd-a9a3-17a2c17452f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MACCS Baseline (166 bits) -> Mean R2: 0.216085, Std: 0.231172\n",
            "\n",
            "=== MACCS SVR (SIGMOID) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim   R2_mean   R2_std\n",
            "baseline       166        166  0.216085 0.231172\n",
            "       1       166        106  0.195889 0.237163\n",
            "       2       166         69  0.167250 0.246002\n",
            "    3_83       166         83  0.043152 0.245977\n",
            "    3_42       166         42 -0.279763 0.298899\n",
            "    4_83       166         64 -0.024914 0.273245\n",
            "    4_42       166         40 -0.346368 0.326515\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_MACCS/summary_results_MACCS.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Daylight"
      ],
      "metadata": {
        "id": "YtP4UtJaz7L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If in Colab, first:  !pip -q install rdkit openpyxl\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit import DataStructs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048                 # Daylight-like FP size\n",
        "MIN_PATH = 1\n",
        "MAX_PATH = 7\n",
        "BRANCHED_PATHS = True\n",
        "\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)   # 0..199\n",
        "\n",
        "# Case-2 thresholds for your ~63-molecule dataset\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "# Cases:\n",
        "# 1: drop never-seen bits\n",
        "# 2: drop never-seen, rare (<3), ubiquitous (>60)\n",
        "# 3_k: fold 2048 -> k by modulo (no dropping)\n",
        "# 4_k: fold, then Case-2 dropping on folded space\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_RDKFP\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_RDKFP.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_daylight(smiles_list, fpSize=N_BITS, minPath=MIN_PATH, maxPath=MAX_PATH, branchedPaths=BRANCHED_PATHS):\n",
        "    \"\"\"Classic RDKit Daylight-like (path) fingerprint -> numpy array (N, fpSize).\"\"\"\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    fps = [Chem.RDKFingerprint(m, fpSize=fpSize, minPath=minPath, maxPath=maxPath,\n",
        "                               branchedPaths=branchedPaths) if m is not None else None\n",
        "           for m in mols]\n",
        "    X = np.zeros((len(fps), fpSize), dtype=np.uint8)\n",
        "    for i, fp in enumerate(fps):\n",
        "        if fp is None:\n",
        "            continue\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X\n",
        "\n",
        "def bit_presence(X):\n",
        "    return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    # count in how many molecules each bit is present\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":        # drop never-seen\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":      # drop never-seen, rare (<3), ubiquitous (>60)\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask):\n",
        "    return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    # modulo hashing: original column j -> j % new_dim\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    \"\"\"Fold columns into new_dim buckets using OR aggregation.\"\"\"\n",
        "    new_dim = int(idx_map.max()) + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    \"\"\"\n",
        "    Case '1': drop never-seen bits\n",
        "    Case '2': drop never-seen, rare (<3), ubiquitous (>60)\n",
        "    Case '3_k': fold to k (no dropping)\n",
        "    Case '4_k': fold to k, then Case-2 dropping on folded space\n",
        "    \"\"\"\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\n",
        "            \"rule\": rule,\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"final_dim\": new_dim,\n",
        "            \"dropped\": 0,\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"rule\": \"case2_after_fold\",\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped_after_fold\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA & BUILD FEATURES\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_daylight(smiles)   # shape (N, 2048)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE: full 2048-bit Daylight FP\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRrbf_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "            X0, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "        )\n",
        "        model = SVR(kernel=\"rbf\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean = float(np.mean(r2s))\n",
        "baseline_std  = float(np.std(r2s))\n",
        "print(f\"Daylight Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 2048-bit RDKit (Daylight-like) FP\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRrbf_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "                X_case, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "            )\n",
        "            model = SVR(kernel=\"rbf\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "\n",
        "    r2_mean = float(np.mean(r2s))\n",
        "    r2_std  = float(np.std(r2s))\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": r2_mean,\n",
        "        \"R2_std\": r2_std,\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== RDKit (Daylight-like) SVR (RBF) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbIf8G6V1KQr",
        "outputId": "77929a87-f1f7-4edb-84a9-87e16324864b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daylight Baseline (2048 bits) -> Mean R2: 0.118657, Std: 0.264341\n",
            "\n",
            "=== RDKit (Daylight-like) SVR (RBF) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim  R2_mean   R2_std\n",
            "baseline      2048       2048 0.118657 0.264341\n",
            "       1      2048       1840 0.117970 0.264966\n",
            "       2      2048       1202 0.132650 0.253330\n",
            "  3_1024      2048       1024 0.101384 0.263624\n",
            "   3_512      2048        512 0.110711 0.279029\n",
            "  4_1024      2048        909 0.104545 0.261213\n",
            "   4_512      2048        510 0.111133 0.279004\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_RDKFP/summary_results_RDKFP.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If in Colab, first:  !pip -q install rdkit openpyxl\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit import DataStructs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048                 # Daylight-like FP size\n",
        "MIN_PATH = 1\n",
        "MAX_PATH = 7\n",
        "BRANCHED_PATHS = True\n",
        "\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)   # 0..199\n",
        "\n",
        "# Case-2 thresholds for your ~63-molecule dataset\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "# Cases:\n",
        "# 1: drop never-seen bits\n",
        "# 2: drop never-seen, rare (<3), ubiquitous (>60)\n",
        "# 3_k: fold 2048 -> k by modulo (no dropping)\n",
        "# 4_k: fold, then Case-2 dropping on folded space\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_RDKFP\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_RDKFP.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_daylight(smiles_list, fpSize=N_BITS, minPath=MIN_PATH, maxPath=MAX_PATH, branchedPaths=BRANCHED_PATHS):\n",
        "    \"\"\"Classic RDKit Daylight-like (path) fingerprint -> numpy array (N, fpSize).\"\"\"\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    fps = [Chem.RDKFingerprint(m, fpSize=fpSize, minPath=minPath, maxPath=maxPath,\n",
        "                               branchedPaths=branchedPaths) if m is not None else None\n",
        "           for m in mols]\n",
        "    X = np.zeros((len(fps), fpSize), dtype=np.uint8)\n",
        "    for i, fp in enumerate(fps):\n",
        "        if fp is None:\n",
        "            continue\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X\n",
        "\n",
        "def bit_presence(X):\n",
        "    return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    # count in how many molecules each bit is present\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":        # drop never-seen\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":      # drop never-seen, rare (<3), ubiquitous (>60)\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask):\n",
        "    return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    # modulo hashing: original column j -> j % new_dim\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    \"\"\"Fold columns into new_dim buckets using OR aggregation.\"\"\"\n",
        "    new_dim = int(idx_map.max()) + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    \"\"\"\n",
        "    Case '1': drop never-seen bits\n",
        "    Case '2': drop never-seen, rare (<3), ubiquitous (>60)\n",
        "    Case '3_k': fold to k (no dropping)\n",
        "    Case '4_k': fold to k, then Case-2 dropping on folded space\n",
        "    \"\"\"\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\n",
        "            \"rule\": rule,\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"final_dim\": new_dim,\n",
        "            \"dropped\": 0,\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"rule\": \"case2_after_fold\",\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped_after_fold\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA & BUILD FEATURES\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_daylight(smiles)   # shape (N, 2048)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE: full 2048-bit Daylight FP\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRlinear_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "            X0, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "        )\n",
        "        model = SVR(kernel=\"linear\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean = float(np.mean(r2s))\n",
        "baseline_std  = float(np.std(r2s))\n",
        "print(f\"Daylight Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 2048-bit RDKit (Daylight-like) FP\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRlinear_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "                X_case, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "            )\n",
        "            model = SVR(kernel=\"linear\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "\n",
        "    r2_mean = float(np.mean(r2s))\n",
        "    r2_std  = float(np.std(r2s))\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": r2_mean,\n",
        "        \"R2_std\": r2_std,\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== RDKit (Daylight-like) SVR (linear) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtTLvo8d1Nxg",
        "outputId": "d6a21ad1-c77a-421b-bb08-75eabab7eb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daylight Baseline (2048 bits) -> Mean R2: 0.206734, Std: 0.408697\n",
            "\n",
            "=== RDKit (Daylight-like) SVR (linear) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim  R2_mean   R2_std\n",
            "baseline      2048       2048 0.206734 0.408697\n",
            "       1      2048       1840 0.206734 0.408697\n",
            "       2      2048       1202 0.208795 0.420486\n",
            "  3_1024      2048       1024 0.165151 0.434407\n",
            "   3_512      2048        512 0.074154 0.469219\n",
            "  4_1024      2048        909 0.160846 0.442117\n",
            "   4_512      2048        510 0.073289 0.469868\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_RDKFP/summary_results_RDKFP.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If in Colab, first:  !pip -q install rdkit openpyxl\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit import DataStructs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048                 # Daylight-like FP size\n",
        "MIN_PATH = 1\n",
        "MAX_PATH = 7\n",
        "BRANCHED_PATHS = True\n",
        "\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)   # 0..199\n",
        "\n",
        "# Case-2 thresholds for your ~63-molecule dataset\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "# Cases:\n",
        "# 1: drop never-seen bits\n",
        "# 2: drop never-seen, rare (<3), ubiquitous (>60)\n",
        "# 3_k: fold 2048 -> k by modulo (no dropping)\n",
        "# 4_k: fold, then Case-2 dropping on folded space\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_RDKFP\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_RDKFP.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_daylight(smiles_list, fpSize=N_BITS, minPath=MIN_PATH, maxPath=MAX_PATH, branchedPaths=BRANCHED_PATHS):\n",
        "    \"\"\"Classic RDKit Daylight-like (path) fingerprint -> numpy array (N, fpSize).\"\"\"\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    fps = [Chem.RDKFingerprint(m, fpSize=fpSize, minPath=minPath, maxPath=maxPath,\n",
        "                               branchedPaths=branchedPaths) if m is not None else None\n",
        "           for m in mols]\n",
        "    X = np.zeros((len(fps), fpSize), dtype=np.uint8)\n",
        "    for i, fp in enumerate(fps):\n",
        "        if fp is None:\n",
        "            continue\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X\n",
        "\n",
        "def bit_presence(X):\n",
        "    return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    # count in how many molecules each bit is present\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":        # drop never-seen\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":      # drop never-seen, rare (<3), ubiquitous (>60)\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask):\n",
        "    return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    # modulo hashing: original column j -> j % new_dim\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    \"\"\"Fold columns into new_dim buckets using OR aggregation.\"\"\"\n",
        "    new_dim = int(idx_map.max()) + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    \"\"\"\n",
        "    Case '1': drop never-seen bits\n",
        "    Case '2': drop never-seen, rare (<3), ubiquitous (>60)\n",
        "    Case '3_k': fold to k (no dropping)\n",
        "    Case '4_k': fold to k, then Case-2 dropping on folded space\n",
        "    \"\"\"\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\n",
        "            \"rule\": rule,\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"final_dim\": new_dim,\n",
        "            \"dropped\": 0,\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\n",
        "            \"folded_to\": new_dim,\n",
        "            \"rule\": \"case2_after_fold\",\n",
        "            \"final_dim\": int(mask.sum()),\n",
        "            \"dropped_after_fold\": int((~mask).sum()),\n",
        "        })\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA & BUILD FEATURES\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_daylight(smiles)   # shape (N, 2048)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE: full 2048-bit Daylight FP\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRsigmoid_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "            X0, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "        )\n",
        "        model = SVR(kernel=\"sigmoid\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean = float(np.mean(r2s))\n",
        "baseline_std  = float(np.std(r2s))\n",
        "print(f\"Daylight Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 2048-bit RDKit (Daylight-like) FP\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRsigmoid_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "                X_case, y, test_size=TEST_SIZE, random_state=int(seed)\n",
        "            )\n",
        "            model = SVR(kernel=\"sigmoid\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "\n",
        "    r2_mean = float(np.mean(r2s))\n",
        "    r2_std  = float(np.std(r2s))\n",
        "\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": r2_mean,\n",
        "        \"R2_std\": r2_std,\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== RDKit (Daylight-like) SVR (sigmoid) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsHk71N51XZ8",
        "outputId": "092503c6-e76e-43a2-bad8-888c0683215d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daylight Baseline (2048 bits) -> Mean R2: 0.112590, Std: 0.267176\n",
            "\n",
            "=== RDKit (Daylight-like) SVR (sigmoid) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim  R2_mean   R2_std\n",
            "baseline      2048       2048 0.112590 0.267176\n",
            "       1      2048       1840 0.110392 0.268001\n",
            "       2      2048       1202 0.107049 0.262094\n",
            "  3_1024      2048       1024 0.073416 0.258831\n",
            "   3_512      2048        512 0.028572 0.264219\n",
            "  4_1024      2048        909 0.068406 0.259214\n",
            "   4_512      2048        510 0.028306 0.264765\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_RDKFP/summary_results_RDKFP.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avalon"
      ],
      "metadata": {
        "id": "kvn4t7qT2Fzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If in Colab, first:  !pip -q install rdkit-pypi openpyxl\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Avalon import pyAvalonTools\n",
        "from rdkit import DataStructs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 1024                  # Avalon default size\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)\n",
        "\n",
        "# For Case 2 thresholds\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "CASES = [\"1\", \"2\", \"3_512\", \"3_256\", \"4_512\", \"4_256\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_Avalon\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_Avalon.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_avalon(smiles_list, nBits=N_BITS):\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    fps = [pyAvalonTools.GetAvalonFP(m, nBits) if m is not None else None for m in mols]\n",
        "    X = np.zeros((len(fps), nBits), dtype=np.uint8)\n",
        "    for i, fp in enumerate(fps):\n",
        "        if fp is None:\n",
        "            continue\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X\n",
        "\n",
        "def bit_presence(X): return (X > 0).astype(np.uint8)\n",
        "def compute_freq_initial_only(X_init): return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask): return X[:, mask]\n",
        "def build_fold_map(orig_dim, new_dim): return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case==\"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\"rule\": rule, \"final_dim\": int(mask.sum()), \"dropped\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\"folded_to\": new_dim, \"final_dim\": new_dim, \"dropped\": 0})\n",
        "        return X_out, meta\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\"folded_to\": new_dim, \"rule\": \"case2_after_fold\",\n",
        "                     \"final_dim\": int(mask.sum()), \"dropped_after_fold\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_avalon(smiles)   # shape (N, 1024)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRrbf_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X0, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "        model = SVR(kernel=\"rbf\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean, baseline_std = float(np.mean(r2s)), float(np.std(r2s))\n",
        "print(f\"Avalon Baseline (1024 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 1024-bit Avalon FP\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRrbf_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(X_case, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "            model = SVR(kernel=\"rbf\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": float(np.mean(r2s)),\n",
        "        \"R2_std\": float(np.std(r2s)),\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== Avalon SVR (RBF) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLfdCNC62Inw",
        "outputId": "431f9287-8f42-426b-cbd0-70564055074f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avalon Baseline (1024 bits) -> Mean R2: 0.114430, Std: 0.252629\n",
            "\n",
            "=== Avalon SVR (RBF) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim  R2_mean   R2_std\n",
            "baseline      1024       1024 0.114430 0.252629\n",
            "       1      1024        581 0.111698 0.253737\n",
            "       2      1024        351 0.139344 0.247125\n",
            "   3_512      1024        512 0.127676 0.251436\n",
            "   3_256      1024        256 0.138115 0.241004\n",
            "   4_512      1024        303 0.145358 0.249111\n",
            "   4_256      1024        221 0.147480 0.239716\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_Avalon/summary_results_Avalon.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If in Colab, first:  !pip -q install rdkit-pypi openpyxl\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Avalon import pyAvalonTools\n",
        "from rdkit import DataStructs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 1024                  # Avalon default size\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)\n",
        "\n",
        "# For Case 2 thresholds\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "CASES = [\"1\", \"2\", \"3_512\", \"3_256\", \"4_512\", \"4_256\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_Avalon\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_Avalon.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_avalon(smiles_list, nBits=N_BITS):\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    fps = [pyAvalonTools.GetAvalonFP(m, nBits) if m is not None else None for m in mols]\n",
        "    X = np.zeros((len(fps), nBits), dtype=np.uint8)\n",
        "    for i, fp in enumerate(fps):\n",
        "        if fp is None:\n",
        "            continue\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X\n",
        "\n",
        "def bit_presence(X): return (X > 0).astype(np.uint8)\n",
        "def compute_freq_initial_only(X_init): return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask): return X[:, mask]\n",
        "def build_fold_map(orig_dim, new_dim): return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case==\"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\"rule\": rule, \"final_dim\": int(mask.sum()), \"dropped\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\"folded_to\": new_dim, \"final_dim\": new_dim, \"dropped\": 0})\n",
        "        return X_out, meta\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\"folded_to\": new_dim, \"rule\": \"case2_after_fold\",\n",
        "                     \"final_dim\": int(mask.sum()), \"dropped_after_fold\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_avalon(smiles)   # shape (N, 1024)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRlinear_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X0, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "        model = SVR(kernel=\"linear\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean, baseline_std = float(np.mean(r2s)), float(np.std(r2s))\n",
        "print(f\"Avalon Baseline (1024 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 1024-bit Avalon FP\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRlinear_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(X_case, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "            model = SVR(kernel=\"linear\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": float(np.mean(r2s)),\n",
        "        \"R2_std\": float(np.std(r2s)),\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== Avalon SVR (linear) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dODJZ5HE2ZY4",
        "outputId": "c2ed1283-e407-4af3-d5f2-bbafe2e13ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avalon Baseline (1024 bits) -> Mean R2: 0.189788, Std: 0.446367\n",
            "\n",
            "=== Avalon SVR (linear) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim   R2_mean   R2_std\n",
            "baseline      1024       1024  0.189788 0.446367\n",
            "       1      1024        581  0.189788 0.446367\n",
            "       2      1024        351  0.166303 0.476478\n",
            "   3_512      1024        512  0.165034 0.419184\n",
            "   3_256      1024        256 -0.039079 0.499682\n",
            "   4_512      1024        303  0.131953 0.430210\n",
            "   4_256      1024        221 -0.076858 0.512474\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_Avalon/summary_results_Avalon.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If in Colab, first:  !pip -q install rdkit-pypi openpyxl\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Avalon import pyAvalonTools\n",
        "from rdkit import DataStructs\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 1024                  # Avalon default size\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)\n",
        "\n",
        "# For Case 2 thresholds\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "CASES = [\"1\", \"2\", \"3_512\", \"3_256\", \"4_512\", \"4_256\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_Avalon\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_Avalon.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_avalon(smiles_list, nBits=N_BITS):\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    fps = [pyAvalonTools.GetAvalonFP(m, nBits) if m is not None else None for m in mols]\n",
        "    X = np.zeros((len(fps), nBits), dtype=np.uint8)\n",
        "    for i, fp in enumerate(fps):\n",
        "        if fp is None:\n",
        "            continue\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X\n",
        "\n",
        "def bit_presence(X): return (X > 0).astype(np.uint8)\n",
        "def compute_freq_initial_only(X_init): return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask): return X[:, mask]\n",
        "def build_fold_map(orig_dim, new_dim): return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case==\"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\"rule\": rule, \"final_dim\": int(mask.sum()), \"dropped\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\"folded_to\": new_dim, \"final_dim\": new_dim, \"dropped\": 0})\n",
        "        return X_out, meta\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\"folded_to\": new_dim, \"rule\": \"case2_after_fold\",\n",
        "                     \"final_dim\": int(mask.sum()), \"dropped_after_fold\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_avalon(smiles)   # shape (N, 1024)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRsigmoid_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X0, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "        model = SVR(kernel=\"sigmoid\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean, baseline_std = float(np.mean(r2s)), float(np.std(r2s))\n",
        "print(f\"Avalon Baseline (1024 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 1024-bit Avalon FP\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRsigmoid_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(X_case, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "            model = SVR(kernel=\"sigmoid\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": float(np.mean(r2s)),\n",
        "        \"R2_std\": float(np.std(r2s)),\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== Avalon SVR (sigmoid) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB27msjf2iog",
        "outputId": "4c00aea9-dd2d-436e-f926-030c219f4113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avalon Baseline (1024 bits) -> Mean R2: 0.099085, Std: 0.292702\n",
            "\n",
            "=== Avalon SVR (sigmoid) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim   R2_mean   R2_std\n",
            "baseline      1024       1024  0.099085 0.292702\n",
            "       1      1024        581  0.083899 0.302781\n",
            "       2      1024        351  0.023829 0.343208\n",
            "   3_512      1024        512 -0.002558 0.358618\n",
            "   3_256      1024        256 -0.062751 0.308133\n",
            "   4_512      1024        303 -0.033459 0.366015\n",
            "   4_256      1024        221 -0.085137 0.316012\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_Avalon/summary_results_Avalon.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AtomPairs"
      ],
      "metadata": {
        "id": "IkgJnSc52wMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If in Colab (run once per runtime):\n",
        "# !pip -q install rdkit openpyxl\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import rdFingerprintGenerator as rfg  # AtomPairGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)  # 0..199\n",
        "\n",
        "# For Case 2 thresholds (your ~63-molecule set)\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "# Cases:\n",
        "# 1: drop never-seen bits\n",
        "# 2: drop never-seen, rare (<3), ubiquitous (>60)\n",
        "# 3_k: fold 2048 -> k by modulo (no dropping)\n",
        "# 4_k: fold, then Case-2 dropping on folded space\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_AtomPairs_Gen\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_AtomPairs_Gen.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_atompairs(smiles_list, nBits=N_BITS, minDistance=1, maxDistance=30, includeChirality=False):\n",
        "    \"\"\"\n",
        "    RDKit AtomPairGenerator -> numpy array (N, nBits).\n",
        "    Distances are in bonds; defaults are typical for AtomPairs.\n",
        "    \"\"\"\n",
        "    gen = rfg.GetAtomPairGenerator(\n",
        "        fpSize=nBits,\n",
        "        minDistance=minDistance,\n",
        "        maxDistance=maxDistance,\n",
        "        includeChirality=includeChirality\n",
        "    )\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    X = np.zeros((len(mols), nBits), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        if m is None:\n",
        "            continue\n",
        "        fp = gen.GetFingerprint(m)                 # ExplicitBitVect\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])  # fills row in-place\n",
        "    return X\n",
        "\n",
        "def bit_presence(X): return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    # in how many molecules each bit is present\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":        # drop never-seen\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":      # drop never-seen, rare (<3), ubiquitous (>60)\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask): return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    # modulo hashing: original column j -> j % new_dim\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    \"\"\"Fold columns into new_dim buckets using OR aggregation (binary fingerprints).\"\"\"\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    \"\"\"\n",
        "    Case '1': drop never-seen bits\n",
        "    Case '2': drop never-seen, rare (<3), ubiquitous (>60)\n",
        "    Case '3_k': fold to k (no dropping)\n",
        "    Case '4_k': fold to k, then Case-2 dropping on folded space\n",
        "    \"\"\"\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\"rule\": rule, \"final_dim\": int(mask.sum()), \"dropped\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\"folded_to\": new_dim, \"final_dim\": new_dim, \"dropped\": 0})\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\"folded_to\": new_dim, \"rule\": \"case2_after_fold\",\n",
        "                     \"final_dim\": int(mask.sum()), \"dropped_after_fold\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_atompairs(smiles)  # (N, 2048)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRrbf_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X0, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "        model = SVR(kernel=\"rbf\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean, baseline_std = float(np.mean(r2s)), float(np.std(r2s))\n",
        "print(f\"AtomPairs (Generator) Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 2048-bit AtomPairs (AtomPairGenerator)\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRrbf_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(X_case, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "            model = SVR(kernel=\"rbf\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": float(np.mean(r2s)),\n",
        "        \"R2_std\": float(np.std(r2s)),\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== AtomPairs (Generator) SVR (RBF) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXppKYD23XPx",
        "outputId": "a05437e1-5712-44ce-cd1f-3af1ceb504be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AtomPairs (Generator) Baseline (2048 bits) -> Mean R2: 0.129293, Std: 0.271291\n",
            "\n",
            "=== AtomPairs (Generator) SVR (RBF) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim  R2_mean   R2_std\n",
            "baseline      2048       2048 0.129293 0.271291\n",
            "       1      2048        480 0.120355 0.272957\n",
            "       2      2048        219 0.164116 0.265656\n",
            "  3_1024      2048       1024 0.146616 0.270217\n",
            "   3_512      2048        512 0.158734 0.267656\n",
            "  4_1024      2048        210 0.174260 0.268691\n",
            "   4_512      2048        184 0.168379 0.272046\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_AtomPairs_Gen/summary_results_AtomPairs_Gen.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If in Colab (run once per runtime):\n",
        "# !pip -q install rdkit openpyxl\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import rdFingerprintGenerator as rfg  # AtomPairGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)  # 0..199\n",
        "\n",
        "# For Case 2 thresholds (your ~63-molecule set)\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "# Cases:\n",
        "# 1: drop never-seen bits\n",
        "# 2: drop never-seen, rare (<3), ubiquitous (>60)\n",
        "# 3_k: fold 2048 -> k by modulo (no dropping)\n",
        "# 4_k: fold, then Case-2 dropping on folded space\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_AtomPairs_Gen\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_AtomPairs_Gen.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_atompairs(smiles_list, nBits=N_BITS, minDistance=1, maxDistance=30, includeChirality=False):\n",
        "    \"\"\"\n",
        "    RDKit AtomPairGenerator -> numpy array (N, nBits).\n",
        "    Distances are in bonds; defaults are typical for AtomPairs.\n",
        "    \"\"\"\n",
        "    gen = rfg.GetAtomPairGenerator(\n",
        "        fpSize=nBits,\n",
        "        minDistance=minDistance,\n",
        "        maxDistance=maxDistance,\n",
        "        includeChirality=includeChirality\n",
        "    )\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    X = np.zeros((len(mols), nBits), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        if m is None:\n",
        "            continue\n",
        "        fp = gen.GetFingerprint(m)                 # ExplicitBitVect\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])  # fills row in-place\n",
        "    return X\n",
        "\n",
        "def bit_presence(X): return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    # in how many molecules each bit is present\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":        # drop never-seen\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":      # drop never-seen, rare (<3), ubiquitous (>60)\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask): return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    # modulo hashing: original column j -> j % new_dim\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    \"\"\"Fold columns into new_dim buckets using OR aggregation (binary fingerprints).\"\"\"\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    \"\"\"\n",
        "    Case '1': drop never-seen bits\n",
        "    Case '2': drop never-seen, rare (<3), ubiquitous (>60)\n",
        "    Case '3_k': fold to k (no dropping)\n",
        "    Case '4_k': fold to k, then Case-2 dropping on folded space\n",
        "    \"\"\"\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\"rule\": rule, \"final_dim\": int(mask.sum()), \"dropped\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\"folded_to\": new_dim, \"final_dim\": new_dim, \"dropped\": 0})\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\"folded_to\": new_dim, \"rule\": \"case2_after_fold\",\n",
        "                     \"final_dim\": int(mask.sum()), \"dropped_after_fold\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_atompairs(smiles)  # (N, 2048)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRlinear_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X0, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "        model = SVR(kernel=\"linear\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean, baseline_std = float(np.mean(r2s)), float(np.std(r2s))\n",
        "print(f\"AtomPairs (Generator) Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 2048-bit AtomPairs (AtomPairGenerator)\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRlinear_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(X_case, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "            model = SVR(kernel=\"linear\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": float(np.mean(r2s)),\n",
        "        \"R2_std\": float(np.std(r2s)),\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== AtomPairs (Generator) SVR (linear) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0bEZQBk30DI",
        "outputId": "ae7fe1dc-8b1b-454c-c9a5-d86658bff503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AtomPairs (Generator) Baseline (2048 bits) -> Mean R2: 0.265278, Std: 0.413454\n",
            "\n",
            "=== AtomPairs (Generator) SVR (linear) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim   R2_mean   R2_std\n",
            "baseline      2048       2048  0.265278 0.413454\n",
            "       1      2048        480  0.265278 0.413454\n",
            "       2      2048        219  0.138232 0.459387\n",
            "  3_1024      2048       1024  0.263502 0.421402\n",
            "   3_512      2048        512  0.175075 0.482534\n",
            "  4_1024      2048        210  0.153155 0.455106\n",
            "   4_512      2048        184 -0.049713 0.590116\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_AtomPairs_Gen/summary_results_AtomPairs_Gen.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If in Colab (run once per runtime):\n",
        "# !pip -q install rdkit openpyxl\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import rdFingerprintGenerator as rfg  # AtomPairGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)  # 0..199\n",
        "\n",
        "# For Case 2 thresholds (your ~63-molecule set)\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "# Cases:\n",
        "# 1: drop never-seen bits\n",
        "# 2: drop never-seen, rare (<3), ubiquitous (>60)\n",
        "# 3_k: fold 2048 -> k by modulo (no dropping)\n",
        "# 4_k: fold, then Case-2 dropping on folded space\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_AtomPairs_Gen\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_AtomPairs_Gen.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_atompairs(smiles_list, nBits=N_BITS, minDistance=1, maxDistance=30, includeChirality=False):\n",
        "    \"\"\"\n",
        "    RDKit AtomPairGenerator -> numpy array (N, nBits).\n",
        "    Distances are in bonds; defaults are typical for AtomPairs.\n",
        "    \"\"\"\n",
        "    gen = rfg.GetAtomPairGenerator(\n",
        "        fpSize=nBits,\n",
        "        minDistance=minDistance,\n",
        "        maxDistance=maxDistance,\n",
        "        includeChirality=includeChirality\n",
        "    )\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    X = np.zeros((len(mols), nBits), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        if m is None:\n",
        "            continue\n",
        "        fp = gen.GetFingerprint(m)                 # ExplicitBitVect\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])  # fills row in-place\n",
        "    return X\n",
        "\n",
        "def bit_presence(X): return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    # in how many molecules each bit is present\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":        # drop never-seen\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":      # drop never-seen, rare (<3), ubiquitous (>60)\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask): return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    # modulo hashing: original column j -> j % new_dim\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    \"\"\"Fold columns into new_dim buckets using OR aggregation (binary fingerprints).\"\"\"\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    \"\"\"\n",
        "    Case '1': drop never-seen bits\n",
        "    Case '2': drop never-seen, rare (<3), ubiquitous (>60)\n",
        "    Case '3_k': fold to k (no dropping)\n",
        "    Case '4_k': fold to k, then Case-2 dropping on folded space\n",
        "    \"\"\"\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\"rule\": rule, \"final_dim\": int(mask.sum()), \"dropped\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\"folded_to\": new_dim, \"final_dim\": new_dim, \"dropped\": 0})\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\"folded_to\": new_dim, \"rule\": \"case2_after_fold\",\n",
        "                     \"final_dim\": int(mask.sum()), \"dropped_after_fold\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_atompairs(smiles)  # (N, 2048)\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRsigmoid_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X0, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "        model = SVR(kernel=\"sigmoid\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean, baseline_std = float(np.mean(r2s)), float(np.std(r2s))\n",
        "print(f\"AtomPairs (Generator) Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 2048-bit AtomPairs (AtomPairGenerator)\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRsigmoid_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(X_case, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "            model = SVR(kernel=\"sigmoid\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": float(np.mean(r2s)),\n",
        "        \"R2_std\": float(np.std(r2s)),\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== AtomPairs (Generator) SVR (sigmoid) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7REtziu39KG",
        "outputId": "9fbd070b-c5a5-4331-b00f-8c449c96d679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AtomPairs (Generator) Baseline (2048 bits) -> Mean R2: 0.192114, Std: 0.254970\n",
            "\n",
            "=== AtomPairs (Generator) SVR (sigmoid) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim   R2_mean   R2_std\n",
            "baseline      2048       2048  0.192114 0.254970\n",
            "       1      2048        480  0.178334 0.260065\n",
            "       2      2048        219  0.088877 0.286364\n",
            "  3_1024      2048       1024  0.193595 0.255544\n",
            "   3_512      2048        512  0.035564 0.284100\n",
            "  4_1024      2048        210  0.093439 0.284564\n",
            "   4_512      2048        184 -0.070000 0.314527\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_AtomPairs_Gen/summary_results_AtomPairs_Gen.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chirality included (new feature introduced in API)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import rdFingerprintGenerator as rfg  # AtomPairGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048\n",
        "INCLUDE_CHIRALITY = True       # << turn chirality on/off here\n",
        "MIN_DISTANCE = 1\n",
        "MAX_DISTANCE = 30\n",
        "\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)    # 0..199\n",
        "\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT = 60\n",
        "\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_AtomPairs_Chiral\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_AtomPairs_Chiral.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_atompairs(smiles_list, nBits=N_BITS,\n",
        "                        minDistance=MIN_DISTANCE, maxDistance=MAX_DISTANCE,\n",
        "                        includeChirality=INCLUDE_CHIRALITY):\n",
        "    \"\"\"AtomPairGenerator -> numpy array (N, nBits) with optional chirality.\"\"\"\n",
        "    gen = rfg.GetAtomPairGenerator(\n",
        "        fpSize=nBits,\n",
        "        minDistance=minDistance,\n",
        "        maxDistance=maxDistance,\n",
        "        includeChirality=includeChirality\n",
        "    )\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    X = np.zeros((len(mols), nBits), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        if m is None:\n",
        "            continue\n",
        "        fp = gen.GetFingerprint(m)\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])\n",
        "    return X\n",
        "\n",
        "def bit_presence(X): return (X > 0).astype(np.uint8)\n",
        "def compute_freq_initial_only(X_init): return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask): return X[:, mask]\n",
        "def build_fold_map(orig_dim, new_dim): return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    new_dim = idx_map.max() + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\"rule\": rule, \"final_dim\": int(mask.sum()), \"dropped\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\"folded_to\": new_dim, \"final_dim\": new_dim, \"dropped\": 0})\n",
        "        return X_out, meta\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\"folded_to\": new_dim, \"rule\": \"case2_after_fold\",\n",
        "                     \"final_dim\": int(mask.sum()), \"dropped_after_fold\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_atompairs(smiles)  # (N, 2048) with chirality\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRrbf_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X0, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "        model = SVR(kernel=\"rbf\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean, baseline_std = float(np.mean(r2s)), float(np.std(r2s))\n",
        "print(f\"AtomPairs (chiral) Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": \"Full 2048-bit AtomPairs (includeChirality=True)\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRrbf_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(X_case, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "            model = SVR(kernel=\"rbf\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": float(np.mean(r2s)),\n",
        "        \"R2_std\": float(np.std(r2s)),\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== AtomPairs (chiral) SVR (RBF) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKl-Wysv4L5u",
        "outputId": "3bd8660d-63dd-44b5-a5f5-41b4f10a1fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AtomPairs (chiral) Baseline (2048 bits) -> Mean R2: 0.140245, Std: 0.269280\n",
            "\n",
            "=== AtomPairs (chiral) SVR (RBF) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim  R2_mean   R2_std\n",
            "baseline      2048       2048 0.140245 0.269280\n",
            "       1      2048        499 0.131316 0.271080\n",
            "       2      2048        217 0.183963 0.263411\n",
            "  3_1024      2048       1024 0.158794 0.268067\n",
            "   3_512      2048        512 0.174627 0.263350\n",
            "  4_1024      2048        207 0.196562 0.268166\n",
            "   4_512      2048        179 0.192094 0.269671\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_AtomPairs_Chiral/summary_results_AtomPairs_Chiral.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torsion"
      ],
      "metadata": {
        "id": "oclUWjZM4sEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If in Colab (once per runtime):\n",
        "# !pip -q install rdkit openpyxl\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import rdFingerprintGenerator as rfg  # TopologicalTorsionGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048\n",
        "INCLUDE_CHIRALITY = False   # set True to encode stereochemistry\n",
        "TORSION_SIZE = 4            # classic topological torsion uses 4-atom fragments\n",
        "\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)  # 0..199\n",
        "\n",
        "# thresholds per your ~63-molecule set\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT  = 60\n",
        "\n",
        "# Cases:\n",
        "# 1: drop never-seen bits\n",
        "# 2: drop never-seen, rare (<3), ubiquitous (>60)\n",
        "# 3_k: fold 2048 -> k by modulo (no dropping)\n",
        "# 4_k: fold, then Case-2 dropping on folded space\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_Torsions\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_Torsions.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_torsions(smiles_list, nBits=N_BITS, torsionSize=TORSION_SIZE, includeChirality=INCLUDE_CHIRALITY):\n",
        "    \"\"\"\n",
        "    RDKit TopologicalTorsionGenerator -> numpy (N, nBits).\n",
        "    torsionSize=4 is the standard; includeChirality toggles stereo.\n",
        "    \"\"\"\n",
        "    gen = rfg.GetTopologicalTorsionGenerator(\n",
        "        fpSize=nBits,\n",
        "        torsionAtomCount=torsionSize,     # sometimes 'atomCount' or 'torsionAtomCount' across RDKit versions\n",
        "        includeChirality=includeChirality\n",
        "    )\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    X = np.zeros((len(mols), nBits), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        if m is None:\n",
        "            continue\n",
        "        fp = gen.GetFingerprint(m)                 # ExplicitBitVect\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])  # fill row in-place\n",
        "    return X\n",
        "\n",
        "def bit_presence(X): return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    # count per-bit presence across molecules\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":        # drop never-seen\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":      # drop never-seen, rare (<3), ubiquitous (>60)\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask): return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    # modulo hashing: original column j -> j % new_dim\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    \"\"\"Fold columns into new_dim buckets using OR aggregation.\"\"\"\n",
        "    new_dim = int(idx_map.max()) + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    \"\"\"\n",
        "    Case '1': drop never-seen bits\n",
        "    Case '2': drop never-seen, rare (<3), ubiquitous (>60)\n",
        "    Case '3_k': fold to k (no dropping)\n",
        "    Case '4_k': fold to k, then Case-2 dropping on folded space\n",
        "    \"\"\"\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\"rule\": rule, \"final_dim\": int(mask.sum()), \"dropped\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\"folded_to\": new_dim, \"final_dim\": new_dim, \"dropped\": 0})\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\"folded_to\": new_dim, \"rule\": \"case2_after_fold\",\n",
        "                     \"final_dim\": int(mask.sum()), \"dropped_after_fold\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_torsions(smiles)  # (N, 2048) topological torsions\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRrbf_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X0, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "        model = SVR(kernel=\"rbf\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean, baseline_std = float(np.mean(r2s)), float(np.std(r2s))\n",
        "print(f\"Torsions Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": f\"Full 2048-bit Topological Torsions (chirality={INCLUDE_CHIRALITY})\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRrbf_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(X_case, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "            model = SVR(kernel=\"rbf\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": float(np.mean(r2s)),\n",
        "        \"R2_std\": float(np.std(r2s)),\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== Topological Torsions SVR (RBF) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJqL9ccR5ErX",
        "outputId": "7ee68e52-399b-43d0-b711-a51e5ada0d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torsions Baseline (2048 bits) -> Mean R2: 0.211189, Std: 0.256045\n",
            "\n",
            "=== Topological Torsions SVR (RBF) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim  R2_mean   R2_std\n",
            "baseline      2048       2048 0.211189 0.256045\n",
            "       1      2048        250 0.203758 0.256504\n",
            "       2      2048         73 0.273915 0.262173\n",
            "  3_1024      2048       1024 0.221129 0.256251\n",
            "   3_512      2048        512 0.232846 0.255752\n",
            "  4_1024      2048         78 0.294915 0.245903\n",
            "   4_512      2048         79 0.267639 0.260383\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_Torsions/summary_results_Torsions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If in Colab (once per runtime):\n",
        "# !pip -q install rdkit openpyxl\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import rdFingerprintGenerator as rfg  # TopologicalTorsionGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048\n",
        "INCLUDE_CHIRALITY = False   # set True to encode stereochemistry\n",
        "TORSION_SIZE = 4            # classic topological torsion uses 4-atom fragments\n",
        "\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)  # 0..199\n",
        "\n",
        "# thresholds per your ~63-molecule set\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT  = 60\n",
        "\n",
        "# Cases:\n",
        "# 1: drop never-seen bits\n",
        "# 2: drop never-seen, rare (<3), ubiquitous (>60)\n",
        "# 3_k: fold 2048 -> k by modulo (no dropping)\n",
        "# 4_k: fold, then Case-2 dropping on folded space\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_Torsions\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_Torsions.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_torsions(smiles_list, nBits=N_BITS, torsionSize=TORSION_SIZE, includeChirality=INCLUDE_CHIRALITY):\n",
        "    \"\"\"\n",
        "    RDKit TopologicalTorsionGenerator -> numpy (N, nBits).\n",
        "    torsionSize=4 is the standard; includeChirality toggles stereo.\n",
        "    \"\"\"\n",
        "    gen = rfg.GetTopologicalTorsionGenerator(\n",
        "        fpSize=nBits,\n",
        "        torsionAtomCount=torsionSize,     # sometimes 'atomCount' or 'torsionAtomCount' across RDKit versions\n",
        "        includeChirality=includeChirality\n",
        "    )\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    X = np.zeros((len(mols), nBits), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        if m is None:\n",
        "            continue\n",
        "        fp = gen.GetFingerprint(m)                 # ExplicitBitVect\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])  # fill row in-place\n",
        "    return X\n",
        "\n",
        "def bit_presence(X): return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    # count per-bit presence across molecules\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":        # drop never-seen\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":      # drop never-seen, rare (<3), ubiquitous (>60)\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask): return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    # modulo hashing: original column j -> j % new_dim\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    \"\"\"Fold columns into new_dim buckets using OR aggregation.\"\"\"\n",
        "    new_dim = int(idx_map.max()) + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    \"\"\"\n",
        "    Case '1': drop never-seen bits\n",
        "    Case '2': drop never-seen, rare (<3), ubiquitous (>60)\n",
        "    Case '3_k': fold to k (no dropping)\n",
        "    Case '4_k': fold to k, then Case-2 dropping on folded space\n",
        "    \"\"\"\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\"rule\": rule, \"final_dim\": int(mask.sum()), \"dropped\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\"folded_to\": new_dim, \"final_dim\": new_dim, \"dropped\": 0})\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\"folded_to\": new_dim, \"rule\": \"case2_after_fold\",\n",
        "                     \"final_dim\": int(mask.sum()), \"dropped_after_fold\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_torsions(smiles)  # (N, 2048) topological torsions\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRlinear_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X0, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "        model = SVR(kernel=\"linear\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean, baseline_std = float(np.mean(r2s)), float(np.std(r2s))\n",
        "print(f\"Torsions Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": f\"Full 2048-bit Topological Torsions (chirality={INCLUDE_CHIRALITY})\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRlinear_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(X_case, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "            model = SVR(kernel=\"linear\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": float(np.mean(r2s)),\n",
        "        \"R2_std\": float(np.std(r2s)),\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== Topological Torsions SVR (linear) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58iIjO0l5Hp7",
        "outputId": "b39a0b35-9d47-4fdf-94b7-bb47e7ac1eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torsions Baseline (2048 bits) -> Mean R2: 0.359225, Std: 0.354232\n",
            "\n",
            "=== Topological Torsions SVR (linear) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim   R2_mean   R2_std\n",
            "baseline      2048       2048  0.359225 0.354232\n",
            "       1      2048        250  0.359225 0.354232\n",
            "       2      2048         73 -0.080918 0.658533\n",
            "  3_1024      2048       1024  0.276438 0.364637\n",
            "   3_512      2048        512  0.247835 0.374568\n",
            "  4_1024      2048         78  0.180351 0.478825\n",
            "   4_512      2048         79  0.150740 0.475900\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_Torsions/summary_results_Torsions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If in Colab (once per runtime):\n",
        "# !pip -q install rdkit openpyxl\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import rdFingerprintGenerator as rfg  # TopologicalTorsionGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# CONFIG\n",
        "# -----------------------------\n",
        "N_BITS = 2048\n",
        "INCLUDE_CHIRALITY = False   # set True to encode stereochemistry\n",
        "TORSION_SIZE = 4            # classic topological torsion uses 4-atom fragments\n",
        "\n",
        "N_SPLITS = 200\n",
        "TEST_SIZE = 0.20\n",
        "SEEDS = np.arange(N_SPLITS)  # 0..199\n",
        "\n",
        "# thresholds per your ~63-molecule set\n",
        "RARE_MIN = 3\n",
        "UBIQ_GT  = 60\n",
        "\n",
        "# Cases:\n",
        "# 1: drop never-seen bits\n",
        "# 2: drop never-seen, rare (<3), ubiquitous (>60)\n",
        "# 3_k: fold 2048 -> k by modulo (no dropping)\n",
        "# 4_k: fold, then Case-2 dropping on folded space\n",
        "CASES = [\"1\", \"2\", \"3_1024\", \"3_512\", \"4_1024\", \"4_512\"]\n",
        "\n",
        "INPUT_XLSX = \"HOMO-LUMO-energies.xlsx\"   # must have columns: Smiles, dFF\n",
        "OUT_DIR = Path(\"ml_runs_dimred_Torsions\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "SUMMARY_CSV = OUT_DIR / \"summary_results_Torsions.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------\n",
        "def smiles_to_torsions(smiles_list, nBits=N_BITS, torsionSize=TORSION_SIZE, includeChirality=INCLUDE_CHIRALITY):\n",
        "    \"\"\"\n",
        "    RDKit TopologicalTorsionGenerator -> numpy (N, nBits).\n",
        "    torsionSize=4 is the standard; includeChirality toggles stereo.\n",
        "    \"\"\"\n",
        "    gen = rfg.GetTopologicalTorsionGenerator(\n",
        "        fpSize=nBits,\n",
        "        torsionAtomCount=torsionSize,     # sometimes 'atomCount' or 'torsionAtomCount' across RDKit versions\n",
        "        includeChirality=includeChirality\n",
        "    )\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    X = np.zeros((len(mols), nBits), dtype=np.uint8)\n",
        "    for i, m in enumerate(mols):\n",
        "        if m is None:\n",
        "            continue\n",
        "        fp = gen.GetFingerprint(m)                 # ExplicitBitVect\n",
        "        DataStructs.ConvertToNumpyArray(fp, X[i])  # fill row in-place\n",
        "    return X\n",
        "\n",
        "def bit_presence(X): return (X > 0).astype(np.uint8)\n",
        "\n",
        "def compute_freq_initial_only(X_init):\n",
        "    # count per-bit presence across molecules\n",
        "    return bit_presence(X_init).sum(axis=0)\n",
        "\n",
        "def select_cols_by_freq(freq, rule):\n",
        "    if rule == \"case1\":        # drop never-seen\n",
        "        return (freq > 0)\n",
        "    elif rule == \"case2\":      # drop never-seen, rare (<3), ubiquitous (>60)\n",
        "        return (freq > 0) & (freq >= RARE_MIN) & (freq <= UBIQ_GT)\n",
        "    else:\n",
        "        raise ValueError(\"rule must be 'case1' or 'case2'\")\n",
        "\n",
        "def apply_mask(X, mask): return X[:, mask]\n",
        "\n",
        "def build_fold_map(orig_dim, new_dim):\n",
        "    # modulo hashing: original column j -> j % new_dim\n",
        "    return np.array([j % new_dim for j in range(orig_dim)], dtype=int)\n",
        "\n",
        "def fold_binary_OR(X, idx_map):\n",
        "    \"\"\"Fold columns into new_dim buckets using OR aggregation.\"\"\"\n",
        "    new_dim = int(idx_map.max()) + 1\n",
        "    out = np.zeros((X.shape[0], new_dim), dtype=np.uint8)\n",
        "    for tgt in range(new_dim):\n",
        "        cols = (idx_map == tgt)\n",
        "        if np.any(cols):\n",
        "            out[:, tgt] = np.max(X[:, cols], axis=1)\n",
        "    return out\n",
        "\n",
        "def transform_case_initial_only(X_init, case):\n",
        "    \"\"\"\n",
        "    Case '1': drop never-seen bits\n",
        "    Case '2': drop never-seen, rare (<3), ubiquitous (>60)\n",
        "    Case '3_k': fold to k (no dropping)\n",
        "    Case '4_k': fold to k, then Case-2 dropping on folded space\n",
        "    \"\"\"\n",
        "    meta = {\"orig_dim\": X_init.shape[1]}\n",
        "    if case in (\"1\", \"2\"):\n",
        "        freq = compute_freq_initial_only(X_init)\n",
        "        rule = \"case1\" if case == \"1\" else \"case2\"\n",
        "        mask = select_cols_by_freq(freq, rule)\n",
        "        X_out = apply_mask(X_init, mask)\n",
        "        meta.update({\"rule\": rule, \"final_dim\": int(mask.sum()), \"dropped\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"3_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_out = fold_binary_OR(X_init, idx_map)\n",
        "        meta.update({\"folded_to\": new_dim, \"final_dim\": new_dim, \"dropped\": 0})\n",
        "        return X_out, meta\n",
        "\n",
        "    elif case.startswith(\"4_\"):\n",
        "        new_dim = int(case.split(\"_\")[1])\n",
        "        idx_map = build_fold_map(X_init.shape[1], new_dim)\n",
        "        X_fold = fold_binary_OR(X_init, idx_map)\n",
        "        freq_fold = compute_freq_initial_only(X_fold)\n",
        "        mask = select_cols_by_freq(freq_fold, \"case2\")\n",
        "        X_out = apply_mask(X_fold, mask)\n",
        "        meta.update({\"folded_to\": new_dim, \"rule\": \"case2_after_fold\",\n",
        "                     \"final_dim\": int(mask.sum()), \"dropped_after_fold\": int((~mask).sum())})\n",
        "        return X_out, meta\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown case: {case}\")\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD DATA\n",
        "# -----------------------------\n",
        "df = pd.read_excel(INPUT_XLSX)\n",
        "smiles = df[\"Smiles\"].astype(str).tolist()\n",
        "y = df[\"dFF\"].values\n",
        "\n",
        "X0 = smiles_to_torsions(smiles)  # (N, 2048) topological torsions\n",
        "\n",
        "# -----------------------------\n",
        "# BASELINE (no reduction)\n",
        "# -----------------------------\n",
        "r2s = []\n",
        "baseline_txt = OUT_DIR / \"r2_SVRsigmoid_baseline.txt\"\n",
        "with open(baseline_txt, \"w\") as f:\n",
        "    f.write(\"# seed\\tR2\\n\")\n",
        "    for seed in SEEDS:\n",
        "        X_tr, X_te, y_tr, y_te = train_test_split(X0, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "        model = SVR(kernel=\"sigmoid\")\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        r2 = r2_score(y_te, y_pred)\n",
        "        r2s.append(r2)\n",
        "        f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "baseline_mean, baseline_std = float(np.mean(r2s)), float(np.std(r2s))\n",
        "print(f\"Torsions Baseline (2048 bits) -> Mean R2: {baseline_mean:.6f}, Std: {baseline_std:.6f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# RUN CASES 1–4\n",
        "# -----------------------------\n",
        "summary_rows = [{\n",
        "    \"Case\": \"baseline\",\n",
        "    \"Orig_Dim\": X0.shape[1],\n",
        "    \"Final_Dim\": X0.shape[1],\n",
        "    \"R2_mean\": baseline_mean,\n",
        "    \"R2_std\": baseline_std,\n",
        "    \"Notes\": f\"Full 2048-bit Topological Torsions (chirality={INCLUDE_CHIRALITY})\"\n",
        "}]\n",
        "\n",
        "for case in CASES:\n",
        "    X_case, meta = transform_case_initial_only(X0, case)\n",
        "    r2s = []\n",
        "    out_txt = OUT_DIR / f\"r2_SVRsigmoid_case{case}.txt\"\n",
        "    with open(out_txt, \"w\") as f:\n",
        "        f.write(\"# seed\\tR2\\n\")\n",
        "        for seed in SEEDS:\n",
        "            X_tr, X_te, y_tr, y_te = train_test_split(X_case, y, test_size=TEST_SIZE, random_state=int(seed))\n",
        "            model = SVR(kernel=\"sigmoid\")\n",
        "            model.fit(X_tr, y_tr)\n",
        "            y_pred = model.predict(X_te)\n",
        "            r2 = r2_score(y_te, y_pred)\n",
        "            r2s.append(r2)\n",
        "            f.write(f\"{int(seed)}\\t{r2:.6f}\\n\")\n",
        "    summary_rows.append({\n",
        "        \"Case\": case,\n",
        "        \"Orig_Dim\": meta.get(\"orig_dim\", X0.shape[1]),\n",
        "        \"Final_Dim\": meta.get(\"final_dim\", X_case.shape[1]),\n",
        "        \"R2_mean\": float(np.mean(r2s)),\n",
        "        \"R2_std\": float(np.std(r2s)),\n",
        "        \"Notes\": {k:v for k,v in meta.items() if k not in [\"orig_dim\",\"final_dim\"]}\n",
        "    })\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE SUMMARY\n",
        "# -----------------------------\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(SUMMARY_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== Topological Torsions SVR (sigmoid) Summary over 200 splits ===\")\n",
        "print(summary_df[[\"Case\",\"Orig_Dim\",\"Final_Dim\",\"R2_mean\",\"R2_std\"]].to_string(index=False))\n",
        "print(f\"\\nSaved summary CSV to: {SUMMARY_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUflEJEm5TnU",
        "outputId": "f4835ed4-68a0-42a5-b60a-fbf0150ca043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torsions Baseline (2048 bits) -> Mean R2: 0.283777, Std: 0.298675\n",
            "\n",
            "=== Topological Torsions SVR (sigmoid) Summary over 200 splits ===\n",
            "    Case  Orig_Dim  Final_Dim  R2_mean   R2_std\n",
            "baseline      2048       2048 0.283777 0.298675\n",
            "       1      2048        250 0.273889 0.303755\n",
            "       2      2048         73 0.104615 0.385871\n",
            "  3_1024      2048       1024 0.311751 0.302179\n",
            "   3_512      2048        512 0.319093 0.285032\n",
            "  4_1024      2048         78 0.207979 0.350605\n",
            "   4_512      2048         79 0.162042 0.337238\n",
            "\n",
            "Saved summary CSV to: ml_runs_dimred_Torsions/summary_results_Torsions.csv\n"
          ]
        }
      ]
    }
  ]
}